{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eeca8f2c",
      "metadata": {
        "id": "eeca8f2c"
      },
      "source": [
        "# Homework: Sentiment Steering and Sparse Autoencoders\n",
        "\n",
        "This assignment explores two mechanistic interpretability techniques:\n",
        "\n",
        "1. Sentiment steering via activation addition.\n",
        "2. Sparse autoencoder on model activations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e20f7913",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e20f7913",
        "outputId": "6ab66dc9-231f-4dec-c0dd-ca0ca3fc98d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.0/192.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers-stream-generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "plum-dispatch 2.6.0 requires beartype>=0.16.2, but you have beartype 0.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q torch matplotlib transformer_lens transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8e063c8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e063c8c",
        "outputId": "cfd08f0c-b49e-440d-89e4-5b624d09955a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model gpt2 into HookedTransformer\n",
            "Moving model to device:  cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HookedTransformer(\n",
              "  (embed): Embed()\n",
              "  (hook_embed): HookPoint()\n",
              "  (pos_embed): PosEmbed()\n",
              "  (hook_pos_embed): HookPoint()\n",
              "  (blocks): ModuleList(\n",
              "    (0-11): 12 x TransformerBlock(\n",
              "      (ln1): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (ln2): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (hook_k): HookPoint()\n",
              "        (hook_q): HookPoint()\n",
              "        (hook_v): HookPoint()\n",
              "        (hook_z): HookPoint()\n",
              "        (hook_attn_scores): HookPoint()\n",
              "        (hook_pattern): HookPoint()\n",
              "        (hook_result): HookPoint()\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (hook_pre): HookPoint()\n",
              "        (hook_post): HookPoint()\n",
              "      )\n",
              "      (hook_attn_in): HookPoint()\n",
              "      (hook_q_input): HookPoint()\n",
              "      (hook_k_input): HookPoint()\n",
              "      (hook_v_input): HookPoint()\n",
              "      (hook_mlp_in): HookPoint()\n",
              "      (hook_attn_out): HookPoint()\n",
              "      (hook_mlp_out): HookPoint()\n",
              "      (hook_resid_pre): HookPoint()\n",
              "      (hook_resid_mid): HookPoint()\n",
              "      (hook_resid_post): HookPoint()\n",
              "    )\n",
              "  )\n",
              "  (ln_final): LayerNormPre(\n",
              "    (hook_scale): HookPoint()\n",
              "    (hook_normalized): HookPoint()\n",
              "  )\n",
              "  (unembed): Unembed()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "from transformer_lens import HookedTransformer\n",
        "import numpy as np\n",
        "\n",
        "model = HookedTransformer.from_pretrained('gpt2')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09247871",
      "metadata": {
        "id": "09247871"
      },
      "source": [
        "## Part 1 – Sentiment Steering via residual (3 points)\n",
        "\n",
        "Your task is to steer model into good/bad generations and see the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a66b9366",
      "metadata": {
        "id": "a66b9366"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "# This is enough to steer! You may experiment with dataset as you want\n",
        "positive_sentences = [\n",
        "    'I love this product, it works wonderfully!',\n",
        "    'This is the best day I have ever had.',\n",
        "    'I am feeling fantastic and everything is great.',\n",
        "    'What a delightful surprise!',\n",
        "    'The food was amazing and the service was excellent.'\n",
        "]\n",
        "\n",
        "negative_sentences = [\n",
        "    'I hate this product, it is terrible.',\n",
        "    'This is the worst day of my life.',\n",
        "    'I am feeling awful and everything is bad.',\n",
        "    'What a horrible experience.',\n",
        "    'The food was disgusting and the service was terrible.'\n",
        "]\n",
        "\n",
        "# Function to collect average residual activations for a list of sentences\n",
        "def collect_average_residuals(sent_list: List[str]):\n",
        "    avgs = [torch.zeros(model.cfg.d_model, device=device) for _ in range(model.cfg.n_layers)]\n",
        "\n",
        "    for sent in sent_list:\n",
        "        toks = model.to_tokens(sent).to(device)\n",
        "        _, cache = model.run_with_cache(toks)\n",
        "        for layer in range(model.cfg.n_layers):\n",
        "            resid_pre = cache[f\"blocks.{layer}.hook_resid_pre\"][0]\n",
        "            avgs[layer] += resid_pre.mean(dim=0)\n",
        "\n",
        "    avgs = [a / len(sent_list) for a in avgs]\n",
        "    return avgs\n",
        "\n",
        "pos_avgs = collect_average_residuals(positive_sentences)\n",
        "neg_avgs = collect_average_residuals(negative_sentences)\n",
        "\n",
        "steering_vectors = [pos - neg for pos, neg in zip(pos_avgs, neg_avgs)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7db63a2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7db63a2a",
        "outputId": "0c4a4b49-98ed-4a4c-ed5a-792c411c3e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral completion:\n",
            "The movie that I watched yesterday was a bit of a disappointment. I was hoping for a more mature, more mature, more mature movie\n",
            "Positive-steered completion:\n",
            "The movie that I watched yesterday was a great one. I was able to watch it with my wife and we were able to watch it\n",
            "Negative-steered completion:\n",
            "The movie that I watched yesterday was a movie about a man who is a serial killer. It was a movie about a man who is\n"
          ]
        }
      ],
      "source": [
        "# Function to generate text with steering applied\n",
        "def generate_with_steering(prompt, max_new_tokens=20, coef=0.0):\n",
        "    tokens = model.to_tokens(prompt).to(device)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Define hooks that add the steering vector times coef at every layer\n",
        "        hooks = []\n",
        "         # Hint: make hooks that add steering vecor with coef to each layer\n",
        "        for layer in range(model.cfg.n_layers):\n",
        "            steer = steering_vectors[layer].to(device)\n",
        "\n",
        "            def make_hook(steer=steer):\n",
        "                def hook(resid, hook):\n",
        "                    resid[:, -1, :] += coef * steer\n",
        "                    return resid\n",
        "                return hook\n",
        "\n",
        "            hooks.append((f\"blocks.{layer}.hook_resid_pre\", make_hook()))\n",
        "\n",
        "        logits = model.run_with_hooks(tokens, fwd_hooks=hooks)\n",
        "        next_token = logits[0, -1].argmax().unsqueeze(0)\n",
        "        tokens = torch.cat([tokens, next_token.unsqueeze(0)], dim=1)\n",
        "\n",
        "        if next_token == model.tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    return model.to_string(tokens[0, 1:])\n",
        "\n",
        "prompt = 'The movie that I watched yesterday was'\n",
        "print('Neutral completion:')\n",
        "print(generate_with_steering(prompt, max_new_tokens=20, coef=0.0))\n",
        "print('Positive-steered completion:')\n",
        "print(generate_with_steering(prompt, max_new_tokens=20, coef=0.3))\n",
        "print('Negative-steered completion:')\n",
        "print(generate_with_steering(prompt, max_new_tokens=20, coef=-0.3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e308de55",
      "metadata": {
        "id": "e308de55"
      },
      "source": [
        "You should see how this is much more effective than tinkering with attantion heads from seminar."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb92929a",
      "metadata": {
        "id": "bb92929a"
      },
      "source": [
        "## Part 2 – Sparse Autoencoder on Residual Activations (4 + bonus)\n",
        "\n",
        "This is compute intensive part and you may adjust hyperparameters to your liking. Try to get meaningful results but in the end it might be compute bound. You still can get max points.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1f48db97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f48db97",
        "outputId": "ebc5ae20-3db2-4f58-8efd-badf5ba583f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total lines: 1000\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "ds = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")\n",
        "texts = ds[\"text\"]\n",
        "\n",
        "texts = [t for t in texts if len(t.strip()) > 0]\n",
        "dataset_sentences = texts[:1000] # You may want to adjust heres\n",
        "\n",
        "print(\"Total lines:\", len(dataset_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "446e5f1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "446e5f1e",
        "outputId": "e5805027-7b41-4138-8ab6-ee4bb815ad36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [01:00, 16.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation dataset shape: torch.Size([103028, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "last_layer = model.cfg.n_layers - 1\n",
        "\n",
        "activations = []\n",
        "token_to_sentence = []\n",
        "with torch.no_grad():\n",
        "    for sent_id, sent in tqdm(enumerate(dataset_sentences)):\n",
        "        tokens = model.to_tokens(sent).to(device)\n",
        "        _, cache = model.run_with_cache(tokens)\n",
        "        # Take the *residual stream* at the last layer\n",
        "        resid = cache[f\"blocks.{last_layer}.hook_resid_pre\"]\n",
        "        activations.append(resid.squeeze(0))\n",
        "        token_to_sentence.extend([sent_id] * resid.shape[1]) # store sent_id per activated token\n",
        "\n",
        "    activations = torch.cat(activations, dim=0)\n",
        "    token_to_sentence = torch.tensor(token_to_sentence)\n",
        "    print('Activation dataset shape:', activations.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ddb1d9f",
      "metadata": {
        "id": "4ddb1d9f"
      },
      "source": [
        "#### Your task is to use any SAE try to disentangle features from residual. In the end you will look at top sentences that activate certain features.\n",
        "\n",
        "Classic approach is enc + relu + dec \\\n",
        "For loss: mse + coef * l1 on hiddden \\\n",
        "But feel free to experiment!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5dfe8a08",
      "metadata": {
        "id": "5dfe8a08"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SAE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
        "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
        "    def forward(self, x):\n",
        "        h = torch.relu(self.encoder(x))\n",
        "        x_recon = self.decoder(h)\n",
        "        return x_recon, h\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6208763b",
      "metadata": {
        "id": "6208763b"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "input_dim = activations.shape[1]\n",
        "hidden_dim = input_dim * 8\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 50\n",
        "\n",
        "sae = SAE(input_dim, hidden_dim).to(device)\n",
        "optimizer = optim.Adam(sae.parameters(), lr=learning_rate)\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    activations_device = activations.to(device)\n",
        "    recon, h = sae(activations_device)\n",
        "\n",
        "    l1_coef = 1e-3\n",
        "    loss = mse(recon, activations_device) + l1_coef * h.abs().mean()\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.6f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27ea52b6",
      "metadata": {
        "id": "27ea52b6"
      },
      "source": [
        "Below is some code that prints tokens that activate certain neuron the most. You are free to change it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "89f8e1c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89f8e1c1",
        "outputId": "a33b59b6-0cef-4a07-e9f5-c5441fac04a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neuron 0:\n",
            "peak token: ' the'\n",
            "context: ... keep themselves alive while at[ the] same time fight to help...\n",
            "Top 1: global token 1468, sentence 10, local token 178\n",
            "<|endoftext|> As the Nameless officially do not exist , the upper echelons of the Gallian Army exploit the concept of plausible deniability in order to send them on missions that would otherwise make Gallia lose face in the war . While at times this works to their advantage , such as a successful incursion into Imperial territory , other orders cause certain members of the 422nd great distress . One such member , Gusurg , becomes so enraged that he abandons his post and defects into the ranks of Calamity Raven , attached to the ideal of Darcsen independence proposed by their leader , Dahau . At the same time , elements within Gallian Army Command move to erase the Nameless in order to protect their own interests . Hounded by both allies and enemies , and combined with the presence of a traitor within their ranks , the 422nd desperately move to keep themselves alive while at the\n",
            "\n",
            "peak token: ' the'\n",
            "context: ... other deities , while at[ the] same time , the multiple...\n",
            "Top 2: global token 41298, sentence 466, local token 152\n",
            "<|endoftext|> Hornung 's arguments have greatly influenced other scholars of Egyptian religion , but some still believe that at times the gods were more unified than he allows . Jan Assmann maintains that the notion of a single deity developed slowly through the New Kingdom , beginning with a focus on Amun @-@ Ra as the all @-@ important sun god . In his view , Atenism was an extreme outgrowth of this trend . It equated the single deity with the sun and dismissed all other gods . Then , in the backlash against Atenism , priestly theologians described the universal god in a different way , one that coexisted with traditional polytheism . The one god was believed to transcend the world and all the other deities , while at the\n",
            "\n",
            "peak token: ' US'\n",
            "context: ... Fey and Richmond purchased a[ US] $ 3 @.@...\n",
            "Top 3: global token 89330, sentence 887, local token 97\n",
            "<|endoftext|> In 1994 , two years after Fey joined Chicago 's Second City improvisational theatre troupe , she began dating Jeff Richmond , a piano player who later became Second City 's musical director and then a composer on 30 Rock . They married in a Greek Orthodox ceremony on June 3 , 2001 . They have two daughters : Alice Zenobia Richmond ( born September 10 , 2005 ) and Penelope Athena Richmond ( born August 10 , 2011 ) . In April 2009 , Fey and Richmond purchased a US\n",
            "\n",
            "peak token: ' Zap'\n",
            "context: ... troops under the pretext that[ Zap]ata failed to demobil...\n",
            "Top 4: global token 71720, sentence 747, local token 137\n",
            "<|endoftext|> Zapata however refused to recognize the interim government of de la Barra , and for the time being the fighting in Morelos continued . Madero met with Zapata on several occasions during June . While initially Zapata trusted Madero , with time he became increasingly concerned that the goals of \" his revolution \" were not being fulfilled . He was particularly angry that Madero did not plan on carrying out any kind of agrarian reform , or the breakup of large hacendias . Additionally , the press in Mexico City , controlled by the landowners began referring to Zapata as a bandit and federal generals , such as Huerta , continued attacking his troops under the pretext that Zap\n",
            "\n",
            "peak token: ' Ll'\n",
            "context: ... Patterson , \" Vargas[ Ll]osa 's expands all...\n",
            "Top 5: global token 77677, sentence 796, local token 172\n",
            "<|endoftext|> Those within the regime are also a mix of fictional characters and real people . President Balaguer is real , but the entire Cabral family is completely fictional . According to Wolff , Vargas Llosa \" uses history as a starting point in constructing a fictionalized account of Trujillo 's \" spiritual colonization \" of the Dominican Republic as experienced by one Dominican family . The fictional Cabral family allows Vargas Llosa to show two sides of the Trujillo regime : through Agustin , the reader sees ultimate dedication and sacrifice to the leader of the nation ; through Urania , the violence of the regime and the legacy of pain it left behind . Vargas Llosa also fictionalized the internal thoughts of the characters who were non @-@ fictional , especially those of the Goat himself . According to literary scholar Richard Patterson , \" Vargas Ll\n",
            "\n",
            "Neuron 1:\n",
            "peak token: ' goddess'\n",
            "context: ... 's air ; the[ goddess] Meretseger oversaw...\n",
            "Top 1: global token 36337, sentence 433, local token 64\n",
            "<|endoftext|> Most Egyptian deities represent natural or social phenomena . The gods were generally said to be immanent in these phenomena — to be present within nature . The types of phenomena they represented include physical places and objects as well as abstract concepts and forces . The god Shu was the deification of all the world 's air ; the goddess\n",
            "\n",
            "peak token: ' goddess'\n",
            "context: ... and the name of the[ goddess] Nekhbet , who...\n",
            "Top 2: global token 38446, sentence 447, local token 70\n",
            "<|endoftext|> In Egyptian belief , names express the fundamental nature of the things to which they refer . In keeping with this belief , the names of deities often relate to their roles or origins . The name of the predatory goddess Sekhmet means \" powerful one \" , the name of the mysterious god Amun means \" hidden one \" , and the name of the goddess\n",
            "\n",
            "peak token: ' because'\n",
            "context: ...<|endoftext|> Perhaps[ because] Abraham Lincoln had not yet...\n",
            "Top 3: global token 5729, sentence 42, local token 2\n",
            "<|endoftext|> Perhaps because\n",
            "\n",
            "peak token: ' does'\n",
            "context: ...izes her situation ; nor[ does] her efficient , perfectionist...\n",
            "Top 4: global token 86072, sentence 855, local token 146\n",
            "<|endoftext|> Fey and former SNL castmate Amy Poehler starred in the 2008 comedy Baby Mama . The movie was written and directed by Michael McCullers . The plot concerns Kate ( Fey ) , a business woman , who wants a child but , discovering she has only a million @-@ to @-@ one chance of getting pregnant , decides to find a surrogate : Angie ( Poehler ) , a white @-@ trash schemer . Baby Mama received mixed reviews , but critics enjoyed Fey 's performance . Todd McCarthy of Variety wrote : \" Fey is a delight to watch throughout . Able to convey Kate 's intentions and feelings through the simple looks and inflections , she never melodramatizes her situation ; nor does\n",
            "\n",
            "peak token: ' Because'\n",
            "context: ... being of other people .[ Because] deities were the upholders...\n",
            "Top 5: global token 43681, sentence 484, local token 221\n",
            "<|endoftext|> Thoth , as the overseer of time , was said to allot fixed lifespans to both humans and gods . Other gods were also said to govern the length of human lives , including Meskhenet , who presided over birth , and Shai , the personification of fate . Thus the time and manner of death was the main meaning of the Egyptian concept of fate , although to some extent these deities governed other events in life as well . Several texts refer to gods influencing or inspiring human decisions , working through a person 's \" heart \" — the seat of emotion and intellect in Egyptian belief . Deities were also believed to give commands , instructing the king in the governance of his realm and regulating the management of their temples . Egyptian texts rarely mention direct commands given to private persons , and these commands never evolved into a set of divinely enforced moral codes . Morality in ancient Egypt was based on the concept of maat , which , when applied to human society , meant that everyone should live in an orderly way that did not interfere with the well @-@ being of other people . Because\n",
            "\n",
            "Neuron 2:\n",
            "peak token: 'j'\n",
            "context: ... to prove himself to Tru[j]illo . Amadito...\n",
            "Top 1: global token 75594, sentence 776, local token 338\n",
            "<|endoftext|> The storyline concerning the assassination primarily follows the four conspirators who directly participate in Trujillo 's death . Antonio Imbert Barrera is one of the few conspirators who survives the violent reprisals that follow Trujillo 's assassination . Imbert is a politician who becomes disillusioned with the deception and cruelty of the Trujillo regime . His first plan to kill Trujillo was foiled by the unsuccessful attempted overthrow of the regime by Cuban paramilitary forces . Now convinced of the difficulty of his task , Imbert joins the other conspirators in plotting Trujillo 's death . Among the others is Antonio de la Maza , one of Trujillo 's personal guards . Antonio 's brother is killed as part of a government cover @-@ up and Antonio swears revenge upon Trujillo . Salvador Estrella Sadhalá , known as \" Turk \" , is a devout Catholic who , in indignation at the regime 's many crimes against God , swears an oath against Trujillo . Turk eventually turns himself in for fear that the regime was torturing his family . Both Turk and his innocent brother are then tortured for months . His father remains loyal to Trujillo and disowns Turk to his face . Despite all of this , Turk refuses to commit suicide and does not lose faith in God . He is later executed by Ramfis and other high level government men . Turk 's close friend , Amado García Guerrero , known as Amadito , is a Lieutenant in the army who gave up his beloved as proof of his loyalty to Trujillo , and then later was forced to kill her brother to prove himself to Truj\n",
            "\n",
            "peak token: 'j'\n",
            "context: ... his own actions during Tru[j]illo 's reign ....\n",
            "Top 2: global token 74656, sentence 770, local token 325\n",
            "<|endoftext|> Urania Cabral and her father Agustín Cabral appear in both the modern day and historical portions of the novel . In the year 1996 , Urania returns to the Dominican Republic for the first time since her departure at the age of 14 . She is a successful New York lawyer who has spent most of the past 35 years trying to overcome the traumas of her childhood , a goal she pursues through an academic fascination with Trujillo and Dominican history . Urania is deeply troubled by the events of her past , and is compelled to confront her father Agustín about his role in those events . Urania visits her father , finding him weakened by age and a severe stroke , so much so that he is barely able to respond physically to her presence , let alone speak . Agustín listens helplessly as Urania recounts his past as \" Egghead Cabral \" , a high @-@ ranking member of Trujillo 's inner circle , and his drastic fall from grace . Urania details Agustín 's role in the events that led to her rape by the Dominican leader , and to her subsequent lifetime of celibacy and emotional trauma . Agustín 's character in the modern day portion of the novel serves primarily as a sounding board for Urania 's recollections of the Trujillo era and the events that surrounded both Agustín Cabral 's disgrace and Urania 's escape from the country . His responses are minimal and non @-@ vocal , despite the ardency of Urania 's accusations and the enormity of his own actions during Truj\n",
            "\n",
            "peak token: 'j'\n",
            "context: ... assassination in 1961 . Tru[j]illo had trained with the...\n",
            "Top 3: global token 73095, sentence 759, local token 85\n",
            "<|endoftext|> The novel examines the dictatorial regime of Rafael Leónidas Trujillo Molina in the Dominican Republic . Trujillo was , in historian Eric Roorda 's words , \" a towering influence in Dominican and Caribbean history \" who presided over \" one of the most durable regimes of the twentieth century \" during the thirty @-@ one years between his seizure of power in 1930 and his assassination in 1961 . Truj\n",
            "\n",
            "peak token: 'j'\n",
            "context: ... storyline and that of Tru[j]illo himself . \n",
            "...\n",
            "Top 4: global token 73750, sentence 764, local token 227\n",
            "<|endoftext|> The Feast of the Goat begins with the return of Urania to her hometown of Santo Domingo , a city which had been renamed Ciudad Trujillo during Trujillo 's time in power . This storyline is largely introspective and deals with Urania 's memories and her inner turmoil over the events preceding her departure from the Dominican Republic thirty @-@ five years earlier . Urania escaped the crumbling Trujillo regime in 1961 by claiming she planned to study under the tutelage of nuns in Michigan . In the following decades , she becomes a prominent and successful New York lawyer . She finally returns to the Dominican Republic in 1996 , on a whim , and finds herself compelled to confront her father and elements of her past she has long ignored . As Urania speaks to her ailing father , Agustin Cabral , she recalls more and more of the anger and disgust that led to her thirty @-@ five years of silence . Urania retells her father 's descent into political disgrace , and the betrayal that forms the crux of both Urania 's storyline and that of Truj\n",
            "\n",
            "peak token: 'j'\n",
            "context: ... is the cause of Tru[j]illo 's repeated anger...\n",
            "Top 5: global token 74153, sentence 766, local token 206\n",
            "<|endoftext|> The third storyline is concerned with the thoughts and motives of Rafael Leónidas Trujillo Molina himself . The chapters concerning The Goat recall the major events of his time , including the slaughter of thousands of Dominican Haitians in 1937 . They also deal with the Dominican Republic 's tense international relationships during the Cold War , especially with the United States under the presidency of John F. Kennedy , and Cuba under Castro . Vargas Llosa also speculates upon Trujillo 's innermost thoughts and paints a picture of a man whose physical body is failing him . Trujillo is tormented by incontinence and impotence ; and this storyline intersects with Urania 's narrative when it is revealed that Urania was sexually assaulted by Trujillo . He is unable to achieve an erection with Urania , and in frustration and anger he rapes her with his hands . This event is the core of Urania 's shame , and her hatred towards her father . In addition , it is the cause of Truj\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sae.eval()\n",
        "with torch.no_grad():\n",
        "    _, h = sae(activations_device)\n",
        "    h = h.cpu().numpy()\n",
        "\n",
        "# For selected neuron indices, find the sentences with highest activation\n",
        "selected_neurons = [0, 1, 2]\n",
        "K = 5\n",
        "\n",
        "SKIP_TOKENS = {\"<|endoftext|>\", \"\\n\"}\n",
        "\n",
        "for neuron in selected_neurons:\n",
        "    activations_neuron = h[:, neuron]\n",
        "    top_idx = activations_neuron.argsort()[::-1]\n",
        "\n",
        "    print(f\"Neuron {neuron}:\")\n",
        "    seen_sents = set()\n",
        "    shown = 0\n",
        "\n",
        "    for idx in top_idx:\n",
        "        sent_id = token_to_sentence[idx].item()\n",
        "        if sent_id in seen_sents:\n",
        "            continue\n",
        "\n",
        "        text = dataset_sentences[sent_id]\n",
        "        toks = model.to_tokens(text)[0]\n",
        "        str_toks = model.to_str_tokens(toks)\n",
        "\n",
        "        token_positions = (token_to_sentence == sent_id).nonzero(as_tuple=True)[0]\n",
        "        local_pos = (token_positions == idx).nonzero(as_tuple=True)[0].item()\n",
        "\n",
        "        peak_tok = str_toks[local_pos]\n",
        "        if peak_tok in SKIP_TOKENS:\n",
        "            continue\n",
        "\n",
        "        left = \"\".join(str_toks[max(0, local_pos-5):local_pos])\n",
        "        right = \"\".join(str_toks[local_pos+1:local_pos+6])\n",
        "        cropped = \"\".join(str_toks[:local_pos + 1])\n",
        "\n",
        "        print(f\"peak token: {repr(peak_tok)}\")\n",
        "        print(f\"context: ...{left}[{peak_tok}]{right}...\")\n",
        "        print(f\"Top {shown+1}: global token {idx}, sentence {sent_id}, local token {local_pos}\")\n",
        "        print(cropped)\n",
        "        print()\n",
        "\n",
        "        seen_sents.add(sent_id)\n",
        "        shown += 1\n",
        "        if shown >= K:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neuron 0: активации максимальны на часто используемх токенах (the, US). Похоже на фичу без чёткой темы — скорее общий паттерн формата.\n",
        "\n",
        "Neuron 1: нейрон часто активируется на словах goddess/god и связках объяснения (because/Because, does). Во-первых, ловит связку египтян со всем божественным, во-вторых, служит для перехода к объясению или расшифровке чего-го.\n",
        "\n",
        "Neuron 2: нейрон активируется на сабтокене 'j' внутри имени Trujillo и похожих контекстов. Это узкая фича на конкретный токен/имя собственное, хорошо интерпретируемая, но очень специфичная."
      ],
      "metadata": {
        "id": "OMrT3E9hXxI2"
      },
      "id": "OMrT3E9hXxI2"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AAX4Xv9XS-GL"
      },
      "id": "AAX4Xv9XS-GL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}